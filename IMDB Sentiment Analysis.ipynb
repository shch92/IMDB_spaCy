{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Sentiment Analysis\n",
    "The project is using the spaCy library to create a sentiment analysis model. The objective is to get familiarized with the spaCy library while creating a model to analyze the sentiments from the reviews of IMDB website.\n",
    "\n",
    "We will start by importing the relevant modules and data below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.base import TransformerMixin \n",
    "from spacy import tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the IMDB data\n",
    "data = pd.read_csv('IMDB Dataset.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the databse to see what it looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataframe to make sure there are no obvious issues\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the dataframe contains 2 columns. The first has the review text and the second shows whether it is a positive or negative review sentiment. Let's ensure these are the only 2 columns by looking at the dataframe structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking the structure of the dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the columns are of object (string) format and contain no missing values. The latter will be confirmed using a sum of the null values in the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see if the dataframe contains any null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the number of duplicated columns below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the total number of duplicates in the dataframe\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to ensure that these are relevant duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>Quite what the producers of this appalling ada...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>My favourite police series of all time turns t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4391</th>\n",
       "      <td>Beautiful film, pure Cassavetes style. Gena Ro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6352</th>\n",
       "      <td>If you liked the Grinch movie... go watch that...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6479</th>\n",
       "      <td>I want very much to believe that the above quo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49912</th>\n",
       "      <td>This is an incredible piece of drama and power...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49950</th>\n",
       "      <td>This was a very brief episode that appeared in...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>Hello it is I Derrick Cannon and I welcome you...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>This movie is a disgrace to the Major League F...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>Les Visiteurs, the first movie about the medie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "3537   Quite what the producers of this appalling ada...  negative\n",
       "3769   My favourite police series of all time turns t...  positive\n",
       "4391   Beautiful film, pure Cassavetes style. Gena Ro...  positive\n",
       "6352   If you liked the Grinch movie... go watch that...  negative\n",
       "6479   I want very much to believe that the above quo...  negative\n",
       "...                                                  ...       ...\n",
       "49912  This is an incredible piece of drama and power...  positive\n",
       "49950  This was a very brief episode that appeared in...  negative\n",
       "49984  Hello it is I Derrick Cannon and I welcome you...  negative\n",
       "49986  This movie is a disgrace to the Major League F...  negative\n",
       "49991  Les Visiteurs, the first movie about the medie...  negative\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualize the duplicates\n",
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates are likely geniune as the reviews are very specific and unique. Therefore the duplicates will be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the duplicates\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also make sure that the sentiment column only has positive or negative sentiment and not others as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that there are only 2 unique values in the sentiment column and those relate to 'positive' and 'negative' sentiment. Now that we know that the basic data is clean, we can check the sentiment distribution as a class imbalance can affect the model choice and model generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcVUlEQVR4nO3deZgdZZ328e8tO7IGAkYhRBZxQROGHgRRQAFfQBFEVkFBcTKMovLiBvOq4AIvuCvIYASGIKhEBwVxBoxBdhQCBggQZHchkrCvKgn3/FFPm0PbS3Un1Z103Z/r6utUPVX11O/kOvn1009V/Y5sExER7fGikQ4gIiKGVxJ/RETLJPFHRLRMEn9ERMsk8UdEtEwSf0REyyTxxzJH0mmSPjOC579V0o5LqK+DJP2iY92SNl0SfZf+npK08ZLqL0YH5T7+aJqk+4D1gYXAU8DFwBG2n6px7KHAB2y/sckYy7kmAPcCT5emp4HrgW/anj7EvlawvWAQxxnYzPZdgzlfOfYy4Bzbpw/22GiXjPhjuOxhezVgErAlcMzIhtOvtUqsE4HpwE/KL6AlStLyS7rPiDqS+GNY2f4zcAnVLwAAJB0t6W5JT0q6TdI7S/urgNOAbcuUxWOl/SxJXyzLO0r6o6SPSZonaa6k93X0vY6kn0l6QtL1kr4o6aq6sdr+JnAccJKkF5U+75O0c1neWtLM0v+Dkr5WDr+ivD5WYt9W0qGSrpb0dUmPAMeVtp7x7C7pHkkPSfpyx3mPk3ROx3ubUKaGlpd0PPAm4JRyvlPKPn+fOpK0pqSzJc2XdL+kT3f0faikqyR9RdKjku6VtFudf6dY9iTxx7CStAGwG9A5lXE3VdJaE/gccI6kcbZvBw4HrrW9mu21+uj2JeXYlwGHAd+WtHbZ9m2qKZuXAIeUn8E6H1gP2LyXbd+kmgpaA9gEmFbaty+va5XYry3rrwfuKf0d38f53gl0Af8E7Am8f6AAbf8/4EqqKbTVbB/Ry24nU/07bQzsALwXeF/H9tcDdwDrAl8CzpCkgc4dy54k/hguP5X0JPAHYB5wbPcG2z+y/YDt522fB9wJbD2Ivp8DPm/7Odv/TXUdYXNJywHvAo61/Yzt24CpQ4j9gfI6po9zbyppXdtP2f71QH3ZPtn2AtvP9rHPSbYfsf174BvAgUOI+QXKv8X+wDG2n7R9H/BV4D0du91v+7u2F1L9O42jujYTo0wSfwyXvWyvDuwIvJJqVAmApPdKmiXpsTKds0Xn9hoe7nEB9RlgNWAssDzVL5tunct1vay8PtLLtsOAVwBzylTS2wfoq875O/e5H3hpjWMGsi6wYumvs++Xdaz/uXvB9jNlcbUlcO5YyiTxx7CyfTlwFvAVAEkbAd8FjgDWKdM5s4HuKYbFue1sPrAA2KCjbcMh9PNOqr9S7ui5wfadtg+kmro5CfixpBfTd9x13k9njONZ9BfH08CqHdteMoi+H6L662SjHn3/qUY8Mcok8cdI+Aawi6RJQHeSnA9QLsxu0bHvg8AGklYc7EnKlMX5VBdRV5X0Sqp57VokrS/pCKppqWNsP9/LPgdLGlu2PVaaF5b38zzVfPpgfULS2pI2BD4KnFfaZwHbSxovaU3+8c6oB/s6X/m3mAYcL2n18gv3KOCc3vaP0S2JP4ad7fnA2cBnyrz7V4FrqRLXa4GrO3a/FLgV+LOkh4ZwuiOoLmj+Gfge8APgrwMc85ikp4FbgN2BfW2f2ce+uwK3SnqK6kLvAbb/UqZKjgeuLlNY2wwi5guAG6gS/c+BMwDKswTnATeX7Rf1OO6bwD7lrpxv9dLvh6n+argHuAr4PtDX+4pRLA9wRatIOgl4ie2h3N0TMSpkxB+jmqRXSnqdKltTXYz9yUjHFTGS8uRgjHarU03vvJTqAu1XqaZSIlorUz0RES2TqZ6IiJZZJqZ6dt11V1988cUjHUZExLKm15Iby8SI/6GHhnIXX0RE9GaZSPwREbHkJPFHRLRMEn9ERMsk8UdEtEwSf0REyyTxR0S0TKP38Uu6D3iSqkztAttdksZQVRicANwH7Gf70SbjiIiIRYZjxP9m25Nsd5X1o4EZtjcDZpT1iIgYJiMx1bMni773dCqw1wjEEBHRWk2XbDDwC0kGvmN7CrC+7bkAtudKWq+3AyVNBiYDjB8/vuEwI0bOhKN/PtIhxFLsvhPftsT7bDrxb2f7gZLcp0uaU/fA8ktiCkBXV9eQS4jmP1X0pYn/UBHLgkanemw/UF7nUX35xdbAg5LGAZTXeU3GEBERL9RY4pf0Ykmrdy8DbwVmAxcC3V97dwj5UoyIiGHV5FTP+sBPJHWf5/u2L5Z0PTBN0mHA74F9G4whIiJ6aCzx274HmNhL+8PATk2dNyIi+pcndyMiWiaJPyKiZZL4IyJaJok/IqJlkvgjIlomiT8iomWS+CMiWiaJPyKiZZL4IyJaJok/IqJlkvgjIlomiT8iomWS+CMiWiaJPyKiZZL4IyJaJok/IqJlkvgjIlomiT8iomWS+CMiWiaJPyKiZZL4IyJaJok/IqJlkvgjIlomiT8iomWS+CMiWiaJPyKiZZL4IyJaJok/IqJlkvgjIlomiT8iomWS+CMiWiaJPyKiZZL4IyJapvHEL2k5Sb+VdFFZHyNpuqQ7y+vaTccQERGLDMeI/6PA7R3rRwMzbG8GzCjrERExTBpN/JI2AN4GnN7RvCcwtSxPBfZqMoaIiHihpkf83wA+CTzf0ba+7bkA5XW93g6UNFnSTEkz58+f33CYERHtMajEL2ltSa+rue/bgXm2bxhKYLan2O6y3TV27NihdBEREb1YfqAdJF0GvKPsOwuYL+ly20cNcOh2wDsk7Q6sDKwh6RzgQUnjbM+VNA6YtzhvICIiBqfOiH9N208AewP/aXsrYOeBDrJ9jO0NbE8ADgAutX0wcCFwSNntEOCCIUUeERFDUifxL19G5vsBFy2Bc54I7CLpTmCXsh4REcNkwKke4PPAJcBVtq+XtDFw52BOYvsy4LKy/DCw0+DCjIiIJaVO4v+Z7R91r9i+B3hXcyFFREST6iT+2ZIeBK4ErgCutv14s2FFRERTBpzjt70pcCBwC/B24CZJsxqOKyIiGlLnds4NqG7NfBMwEbgVuKrhuCIioiF1pnp+D1wPnGD78IbjiYiIhtW5nXNL4Gzg3ZKulXS2pMMajisiIhoy4Ijf9k2S7gbuppruORjYHjij4dgiIqIBdeb4ZwIrAddQze1vb/v+pgOLiIhm1Jnj3812ymNGRIwSdeb4XyTpDEn/AyDp1Znjj4hYdtVJ/GdRlWx4aVn/HXBkQ/FERETD6iT+dW1Po3yZiu0FwMJGo4qIiMbUSfxPS1oHMICkbYCUbIiIWEbVubh7FFUN/U0kXQ2MBfZpNKqIiGhMnfv4b5S0A7A5IOAO2881HllERDSiz8Qv6S22L5W0d49Nr5CE7fMbji0iIhrQ34h/B+BSYI9ethlI4o+IWAb1mfhtH1sWP2A7d/FERIwSde7quVfSFEk7SVLjEUVERKPqJP7NgV8CH6L6JXCKpDc2G1ZERDSlzjdwPWt7mu29qUo0rwFc3nhkERHRiDojfiTtIOlU4EZgZWC/RqOKiIjG1CnLfC8wC5gGfML2000HFRERzanz5O5E2080HklERAyLOlM9L5E0Q9JsAEmvk/TphuOKiIiG1En83wWOAZ4DsH0zcECTQUVERHPqJP5VbV/Xo21BE8FERETz6iT+hyRtwqKyzPsAcxuNKiIiGlPn4u6HgCnAKyX9CbgXOKjRqCIiojF1yjLfA+ws6cVUfyE8C+wP3N9wbBER0YA+p3okrSHpmFKiYRfgGeAQ4C7yAFdExDKrvxH/94BHgWuBfwE+CawI7GV7VvOhRUREE/pL/Bvbfi2ApNOBh4Dxtp+s07GklYErgJXKeX5s+1hJY4DzgAnAfcB+th8d8juIiIhB6e+unr9/vWKpx39v3aRf/BV4i+2JwCRg1/JF7UcDM2xvBswo6xERMUz6G/FPlNRdqkHAKmVdgG2v0V/Htg08VVZXKD8G9gR2LO1TgcuATw0l+IiIGLz+voFrucXtXNJywA3ApsC3bf9G0vq255ZzzJW0Xh/HTgYmA4wfP35xQ4mIiKJWWeahsr3Q9iRgA2BrSVsM4tgptrtsd40dO7axGCMi2qbRxN/N9mNUUzq7Ag9KGgdQXucNRwwREVHp7z7+lRanY0ljJa1VllcBdgbmABdSPQ9Aeb1gcc4TERGD09+I/1oASd8bYt/jgF9Juhm4Hphu+yLgRGAXSXcCu5T1iIgYJv3d1bOipEOAN0jau+dG2+f313Ep37xlL+0PAzsNNtCIiFgy+kv8h1MVY1sL2KPHNgP9Jv6IiFg69Xc751XAVZJm2j5jGGOKiIgG1SnL/D1JHwG2L+uXA6fZfq6fYyIiYilVJ/GfSvXU7all/T3AfwAfaCqoiIhoTp3E/8+l3k63SyXd1FRAERHRrDoPcC0sX70IgKSNgYXNhRQREU2qM+L/BNX9+PdQFWjbCHhfo1FFRERj6nz14gxJmwGbUyX+Obb/2nhkERHRiDojfkqiv7nhWCIiYhgMS5G2iIhYeiTxR0S0zICJX5WDJX22rI+XtHXzoUVERBPqjPhPBbYFDizrTwLfbiyiiIhoVJ2Lu6+3/U+Sfgtg+1FJKzYcV0RENKTOiP+58t25huoLVoDnG40qIiIaUyfxfwv4CbCepOOBq4ATGo0qIiIaU+cBrnMl3UD15SkC9rJ9e+ORRUREIwZM/JLGUH0h+g862lZIWeaIiGVTnameG4H5wO+AO8vyvZJulLRVk8FFRMSSVyfxXwzsbntd2+sAuwHTgA+yqEZ/REQsI+ok/i7bl3Sv2P4FsL3tXwMrNRZZREQ0os59/I9I+hTww7K+P/BoucUzt3VGRCxj6oz43w1sAPwUuAAYX9qWA/ZrLLKIiGhEnds5HwI+3Mfmu5ZsOBER0bQ6t3OOBT4JvAZYubvd9lsajCsiIhpSZ6rnXGAO8HLgc8B9wPUNxhQREQ2qk/jXsX0G8Jzty22/H9im4bgiIqIhde7q6X5Cd66ktwEPUF3sjYiIZVCdxP9FSWsCHwNOBtYAjmwyqIiIaE6dxP+o7ceBx4E3A0jartGoIiKiMXXm+E+u2RYREcuAPkf8krYF3gCMlXRUx6Y1qB7eioiIZVB/I/4VgdWofjms3vHzBLDPQB1L2lDSryTdLulWSR8t7WMkTZd0Z3lde/HfRkRE1NXniN/25cDlks6yff8Q+l4AfMz2jZJWB26QNB04FJhh+0RJRwNHA58aQv8RETEEdS7uriRpCjChc/+Bnty1PReYW5aflHQ78DJgT2DHsttU4DKS+CMihk2dxP8j4DTgdGDhUE4iaQKwJfAbYP3ySwHbcyWt18cxk4HJAOPHjx/KaSMiohd1Ev8C2/8x1BNIWg34L+BI209IqnWc7SnAFICuri4P9fwREfFCdW7n/JmkD0oaVy7MjinfwzsgSStQJf1zbZ9fmh+UNK5sH0f1fb4RETFM6oz4Dymvn+hoM7BxfwepGtqfAdxu+2sdmy4sfZ5YXi+oHW1ERCy2OvX4Xz7EvrcD3gPcImlWaft3qoQ/TdJhwO+BfYfYf0REDEGdevyrAkcB421PlrQZsLnti/o7zvZVQF8T+jsNOtKIiFgi6szx/yfwN6qneAH+CHyxsYgiIqJRdRL/Jra/RCnPbPtZ+h7JR0TEUq5O4v+bpFWoLugiaRPgr41GFRERjalzV8+xwMXAhpLOpbpoe2iTQUVERHPq3NUzXdKNVF+3KOCjth9qPLKIiGjEgFM9kt5J9fTuz8udPAsk7dV4ZBER0Yg6c/zHlm/gAsD2Y1TTPxERsQyqk/h726fOtYGIiFgK1Un8MyV9TdImkjaW9HXghqYDi4iIZtRJ/B+meoDrPGAa8CzwoSaDioiI5vQ7ZSNpOeAC2zsPUzwREdGwfkf8thcCz0hac5jiiYiIhtW5SPsXqgqb04Gnuxttf6SxqCIiojF1Ev/Py09ERIwCdZ7cnVpq9Yy3fccwxBQREQ2q8+TuHsAsqno9SJok6cKG44qIiIbUuZ3zOGBr4DEA27OAoX4rV0REjLA6iX9BZ8mGwk0EExERzatzcXe2pHcDy5WvXfwIcE2zYUVERFPqPrn7GqovX/k+8DhwZIMxRUREg/oc8UtaGTgc2BS4BdjW9oLhCiwiIprR34h/KtBFlfR3A74yLBFFRESj+pvjf7Xt1wJIOgO4bnhCioiIJvU34n+ueyFTPBERo0d/I/6Jkp4oywJWKesCbHuNxqOLiIglrs/Eb3u54QwkIiKGR53bOSMiYhRJ4o+IaJkk/oiIlknij4homST+iIiWSeKPiGiZxhK/pDMlzZM0u6NtjKTpku4sr2s3df6IiOhdkyP+s4Bde7QdDcywvRkwo6xHRMQwaizx274CeKRH855Uxd8or3s1df6IiOjdcM/xr297LkB5XW+Yzx8R0XpL7cVdSZMlzZQ0c/78+SMdTkTEqDHcif9BSeMAyuu8vna0PcV2l+2usWPHDluAERGj3XAn/guBQ8ryIcAFw3z+iIjWa/J2zh8A1wKbS/qjpMOAE4FdJN0J7FLWIyJiGPVXj3+x2D6wj007NXXOiIgY2FJ7cTciIpqRxB8R0TJJ/BERLZPEHxHRMkn8EREtk8QfEdEySfwRES2TxB8R0TJJ/BERLZPEHxHRMkn8EREtk8QfEdEySfwRES2TxB8R0TJJ/BERLZPEHxHRMkn8EREtk8QfEdEySfwRES2TxB8R0TJJ/BERLZPEHxHRMkn8EREtk8QfEdEySfwRES2TxB8R0TJJ/BERLZPEHxHRMkn8EREtk8QfEdEySfwRES2TxB8R0TJJ/BERLTMiiV/SrpLukHSXpKNHIoaIiLYa9sQvaTng28BuwKuBAyW9erjjiIhoq5EY8W8N3GX7Htt/A34I7DkCcUREtNLyI3DOlwF/6Fj/I/D6njtJmgxMLqtPSbpjGGJrg3WBh0Y6iKWBThrpCKIP+Yx2WMzP6cW2d+3ZOBKJX720+R8a7CnAlObDaRdJM213jXQcEX3JZ7R5IzHV80dgw471DYAHRiCOiIhWGonEfz2wmaSXS1oROAC4cATiiIhopWGf6rG9QNIRwCXAcsCZtm8d7jhaLNNnsbTLZ7Rhsv9hej0iIkaxPLkbEdEySfwRES2TxN9iktaS9MGO9ZdK+vFIxhTtJelwSe8ty4dKemnHttPzhP+Skzn+FpM0AbjI9hYjHUtEJ0mXAR+3PXOkYxmNMuJfikmaIOl2Sd+VdKukX0haRdImki6WdIOkKyW9suy/iaRfS7pe0uclPVXaV5M0Q9KNkm6R1F0i40RgE0mzJH25nG92OeY3kl7TEctlkraS9GJJZ5Zz/Lajr2ix8tmZI2mqpJsl/VjSqpJ2Kp+TW8rnZqWy/4mSbiv7fqW0HSfp45L2AbqAc8tnc5Xy+euS9G+SvtRx3kMlnVyWD5Z0XTnmO6UuWPTGdn6W0h9gArAAmFTWpwEHAzOAzUrb64FLy/JFwIFl+XDgqbK8PLBGWV4XuIvqCeoJwOwe55tdlv8v8LmyPA74XVk+ATi4LK8F/A548Uj/W+VnqfisGtiurJ8JfJqqPMsrStvZwJHAGOAOFs04rFVej6Ma5QNcBnR19H8Z1S+DsVS1vrrb/wd4I/Aq4GfACqX9VOC9I/3vsrT+ZMS/9LvX9qyyfAPVf7A3AD+SNAv4DlViBtgW+FFZ/n5HHwJOkHQz8EuqeknrD3DeacC+ZXm/jn7fChxdzn0ZsDIwfnBvKUapP9i+uiyfA+xE9fn9XWmbCmwPPAH8BThd0t7AM3VPYHs+cI+kbSStA2wOXF3OtRVwffls7gRsvPhvaXQaiVo9MTh/7VheSJWwH7M9aRB9HEQ1UtrK9nOS7qNK2H2y/SdJD0t6HbA/8K9lk4B32U7RvOip1gVDVw9xbk2VnA8AjgDeMojznEc1GJkD/MS2JQmYavuYQcbcShnxL3ueAO6VtC+AKhPLtl8D7yrLB3QcsyYwryT9NwMblfYngdX7OdcPgU8Ca9q+pbRdAny4/EdD0paL+4Zi1BgvaduyfCDVX5cTJG1a2t4DXC5pNarP1H9TTf1M6qWv/j6b5wN7lXOcV9pmAPtIWg9A0hhJG/V+eCTxL5sOAg6TdBNwK4u+z+BI4ChJ11FN/zxe2s8FuiTNLMfOAbD9MHC1pNmSvtzLeX5M9QtkWkfbF4AVgJvLheAvLMk3Fsu024FDypTiGODrwPuopiVvAZ4HTqNK6BeV/S6nup7U01nAad0Xdzs32H4UuA3YyPZ1pe02qmsKvyj9TmfRFGj0kNs5RxFJqwLPlj99D6C60Ju7bqJxuTV42ZI5/tFlK+CUMg3zGPD+kQ0nIpZGGfFHRLRM5vgjIlomiT8iomWS+CMiWiaJP0aMpIXldr3Zkn4maa0h9vN5STsv4dh2kzSz1Eqa07OezBD665L0rbK8kqRflve+v4ZYeVLSJEm7d6y/Q9LRg+0n2icXd2PESHrK9mpleSpVPaDjRzgsJG0BXAC8zfYcScsDk22fKuk4qhpIX1mM/rcBTrK9w2LGeShVPZsjFqefaJ+M+GNpcS1VDaHuKqMvqD4qaU1J90l6UdlnVUl/kLSCpLNKRUdUVRC9vBx7iaRxktaTdEPZPlGSJY0v63eX5x86fRI43nb3g24LbJ/aM2BJ/6KqSulNkv6rux9J+5a/Ym6SdEVp21HSReXJ0nOASWXEv4lK5cmy366qqqjeJGlGadta0jWqqlxeI2lzSSsCnwf27/jL4VBJp5RjNlJVkfXm8tr9fs+S9K3Szz3d/27RLkn8MeJUlc/dCbiwNE0BPmx7K+DjwKm2HwduArpHyXsAl9h+rqOfFYCTgX3KsWdSJfB5wMqS1gDeBMwE3lQe6Z9nu2eRsC2oCuIN5Hzb/2x7ItVTq4eV9s8C/6e0v6PzgBLLB4ArbU+yfXdH/GOB71LVQprIoiJ5c4DtbW9Z+j7B9t/K8nmln/N4oVOAs22/jurJ7W91bBtHVdHy7VSluaNl8gBXjKRVVFVSnECVaKerquPSXX20e7+Vyut5VAXjfkVVSqLnKHxzqqQ9vRy7HDC3bLsG2I6qOuQJwK5UBeeuXIz4t5D0Rary1KtR1TGCqlrkWZKmUdWVqWsb4Arb9wLYfqS0rwlMlbQZVSG0FWr0tS2wd1n+HvCljm0/tf08cJukgaq0xiiUEX+MpGdLldGNgBWBD1F9Jh8ro9jun1eV/S8EdpM0huop5Ut79Cfg1o7jXmv7rWXblVSj/Y2o5u8nUo16r+glrltL/wM5CzjC9muBz1Eqnto+nKpuzIbALFXlg+sQvVe4/ALwq1IOYQ8GqKzah85+Oyu+queOMfol8ceIK9M4H6Ga1nmWPqqP2n4KuA74JlVdmIU9uroDGKtSIbLM/3d/i9gVVF9ic2cZ7T4C7E41Ou/py8C/S3pF6edFko7qZb/Vgblliumg7kZJm9j+je3PAg9R/QKo41pgB0kvL/2MKe1rAn8qy4d27N9fBctrWFSh9SDgqpoxRAsk8cdSwfZvqebwD6Dv6qNQTfcczKJyvJ19/A3YBzipHDuLatoI2/eV3bpH+FdR/WXxaC/93ExV6fQHkm4HZtN7pcfPAL+hqgQ5p6P9y6q+anB2Od9N/b/7v593PjAZOL/E3/0evwT8f0lXU01fdfsV8Orui7s9uvsI8D5VlSrfA3y0TgzRDrmdMyKiZTLij4homST+iIiWSeKPiGiZJP6IiJZJ4o+IaJkk/oiIlknij4homf8FEpWz80+vPcwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check Class imbalance for the sentiment\n",
    "values, counts = np.unique(data['sentiment'], return_counts=True)\n",
    "normalized_counts = counts/counts.sum()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(values, normalized_counts * 100)\n",
    "plt.xlabel('Review Clasification')\n",
    "plt.ylabel('Percentage of Reviews')\n",
    "sns.despine()\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the class is perfectly balanced as this is a kaggle dataset. It is highly unlikely that the data in the real world will require this little cleaning. \n",
    "\n",
    "## Preprocessing\n",
    "Let's start with the preprocessing of the data to make it modelling worthy. The preprocessing will be done using spaCy. Overall the steps to preprocess are:\n",
    "1. Encode the `sentiment` column;\n",
    "2. Remove stop words from the reviews;\n",
    "3. Remove punctuation from the reviews;\n",
    "4.\n",
    "\n",
    "\n",
    "### Encode the `sentiment` column\n",
    "Let's start  with step 1 where the `sentiment` is encoded. We will map '0' for negatvie sentiment and '1' for a positive sentiment, this will be done by creating a dictionary for replacing the terms with the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary that we will use to replace the sentiment strings\n",
    "sentiment_vector = {\"negative\":0, \"positive\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the sentiment column in place using the replace method\n",
    "data.replace({\"sentiment\": sentiment_vector}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure the data looks correct\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49582 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     49582 non-null  object\n",
      " 1   sentiment  49582 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Ensure that the data type of the sentiment column is correct\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words from the reviews\n",
    "Now that we have successfully encoded the `sentiment` column, let's remove the stop words from the `reviews` column. We will use spaCy to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'amount', 'where', 'on', 'name', 'herself', 'before', 'never', 'back', 'down', 'give', 'how', 'the', 'in', '‘s', 'twelve', 'are', 'almost', 'whoever', 'either', 'he', 'neither', 'while', 'would', 'each', 'take', 'must', 'himself', 'when', 'two', 'thereupon', 'eleven', 'such', 'onto', 'which', 'everywhere', 'become', 'to', 'seemed', 'well', 'hereupon', 'and', 'any', 'ours', 'than', 'against', 'you', 'others', 'whereas', 'most', 'whom', 'beyond', 'hereafter', 'anyway', 'also', 'afterwards', '‘d', 'front', 'still', 'n’t', 'even', 'unless', 'serious', \"n't\", 'seeming', 'otherwise', 'it', 'itself', 'at', \"'m\", 'all', 'make', 'part', 'doing', 'four', 'them', 'yourselves', 'not', 'she', 'has', 'formerly', 'everything', 'over', 'should', 'hence', 'none', 'about', 'becomes', 'your', 'whereafter', '’ll', 'call', 'out', 'will', 'this', 'few', 'anyone', 'every', 'with', \"'ve\", 'beforehand', 'please', 'elsewhere', 'show', 'could', 'from', \"'ll\", 'made', 'quite', 'wherever', 'various', 'across', 'were', 'nor', 'these', 'without', 'as', 'him', 'whenever', 'below', \"'d\", 'whole', 'a', '‘ve', 'ever', 'sometimes', 'myself', 'towards', 'had', 'alone', 'whither', 'yourself', 'those', 'did', 'became', 'together', 'nobody', 'under', \"'re\", 'becoming', 'for', 'who', 'top', 'until', 'around', 'whose', 'nevertheless', 'themselves', 'is', 'much', 'everyone', 'thereafter', 'so', 'we', 'something', 'another', 'first', 'thereby', 'us', 'fifty', 'just', 'hers', 'whereupon', 'keep', '’ve', 'both', 'during', 'nowhere', 'always', 'further', 'yours', \"'s\", 'though', 'after', 'been', 'hereby', 'through', 'throughout', 'moreover', 'nine', 'now', 'else', 'five', 'too', 'fifteen', 'hundred', 'many', 'latter', 'per', 'enough', 'eight', 'twenty', 'mostly', 'already', 'ten', 'former', 'rather', 'into', 'my', 'very', 'whereby', 'ca', 'have', '’re', '’m', 'what', 'its', 'regarding', 'or', 'say', 'empty', 'move', 'via', 'here', 'by', 'seems', 'no', 'meanwhile', 'do', 'nothing', 'several', 'put', 'was', 'anywhere', 'up', 'less', 'his', 'does', 'bottom', 'yet', 'off', 'among', 'noone', 'really', 'using', 'besides', 'of', 'other', 'ourselves', 'wherein', 'therein', 'thence', 'mine', 'go', 'perhaps', 'behind', 'next', 'anyhow', 'same', 'am', 'three', '’s', 'because', 'herein', 'between', 'namely', 'forty', 'someone', 'somehow', 'but', 'latterly', 'seem', 'their', 'i', 're', 'see', 'cannot', 'why', '‘ll', 'whence', 'amongst', 'our', 'due', '‘re', 'some', 'side', 'upon', 'except', 'one', 'that', '’d', 'again', 'last', 'thru', 'be', 'thus', 'there', 'used', 'whatever', 'sometime', 'done', 'an', 'her', 'toward', 'however', 'own', 'indeed', 'along', 'they', 'being', 'somewhere', 'full', 'therefore', 'might', 'although', 'once', 'more', 'sixty', 'six', 'me', 'can', 'within', 'least', 'above', '‘m', 'third', 'may', 'since', 'n‘t', 'beside', 'get', 'anything', 'then', 'often', 'if', 'whether']\n"
     ]
    }
   ],
   "source": [
    "#Visualize the stopwords\n",
    "from  spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords = list(STOP_WORDS)\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above the stop words and there are 326 potential which will be removed if found in the reviews. \n",
    "\n",
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the punctuations of string module\n",
    "import string\n",
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Spacy Parser\n",
    "from spacy.lang.en import English\n",
    "parser = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tokenizer(sentence):\n",
    "    mytokens = parser(sentence)\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    mytokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom transformer using spaCy \n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text \n",
    "def clean_text(text):     \n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = CountVectorizer(tokenizer = spacy_tokenizer) \n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidf\n",
    "#tfvectorizer = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = data['review']\n",
    "ylabels = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  pipeline to clean, tokenize, vectorize, and classify \n",
    "pipe = Pipeline([('cleaner', predictors()),\n",
    "                 ('vectorizer', vectorizer),\n",
    "                 ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39665,)\n",
      "(9917,)\n",
      "(39665,)\n",
      "(9917,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a82d6a57df4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    293\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1127\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m   1130\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# Fit our data\n",
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting with a test dataset\n",
    "sample_prediction = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Results\n",
    "# 1 = Positive review\n",
    "# 0 = Negative review\n",
    "for (sample,pred) in zip(X_test,sample_prediction):\n",
    "    print(sample,\"Prediction=>\",pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
